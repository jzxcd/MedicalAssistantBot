{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "941da594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from src.llm_helper import invoke_llm, max_seq_length\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from src.helper import rouge_lsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a409f29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    'json', \n",
    "    data_files={\n",
    "        'test': 'data/test.jsonl'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269aa12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.8.9: Fast Gemma3 patching. Transformers: 4.55.4.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 1. Max memory: 23.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "ft_model, ft_tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"saved_models/full_model2\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = False,\n",
    "    load_in_8bit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01d66022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.8.9: Fast Gemma3 patching. Transformers: 4.55.4.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 1. Max memory: 23.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "base_model, base_tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-3-270m-it\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = False,\n",
    "    load_in_8bit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57baeb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [13:40<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# inference - base \n",
    "base_test_res = []\n",
    "for example in tqdm(dataset['test']):\n",
    "    answer = invoke_llm(example['instruction'], base_model, base_tokenizer)\n",
    "    S = rouge_lsum(answer, example['output'])\n",
    "    base_test_res.append([S.precision, S.recall, S.fmeasure, example['instruction'], example['output'], answer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee842676",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame(base_test_res).to_csv('_base_test_res', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba2c3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:13<3:40:16, 13.23s/it]"
     ]
    }
   ],
   "source": [
    "# inference - fine tuned\n",
    "ft_test_res = []\n",
    "for example in tqdm(dataset['test']):\n",
    "    answer = invoke_llm(example['instruction'], ft_model, ft_tokenizer)\n",
    "    S = rouge_lsum(answer, example['output'])\n",
    "    ft_test_res.append([S.precision, S.recall, S.fmeasure, example['instruction'], example['output'], answer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62ebcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(ft_res, base_res, score_idx):\n",
    "    eval_df = pd.DataFrame(columns = [\n",
    "        'ft_precision', 'ft_recall', 'ft_fscore', \n",
    "        'base_precision', 'base_recall', 'base_fscore',\n",
    "        'query', 'answer', \n",
    "        'pred_ft', 'pred_base'\n",
    "    ])\n",
    "    for i in range(len(ft_res)):\n",
    "        ft_precision, ft_recall, ft_fscore = ft_res[i][0], ft_res[i][1], ft_res[i][2]\n",
    "        base_precision, base_recall, base_fscore = base_res[i][0], base_res[i][1], base_res[i][2]\n",
    "        base_score = base_res[i][score_idx]\n",
    "        query, answer = ft_res[i][3], ft_res[i][4]\n",
    "        pred_ft = ft_res[i][-1]\n",
    "        pred_base = base_res[i][-1]\n",
    "        eval_df.loc[i] = [\n",
    "            ft_precision, ft_recall, ft_fscore, \n",
    "            base_precision, base_recall, base_fscore, \n",
    "            query, answer, \n",
    "            pred_ft, pred_base\n",
    "        ]\n",
    "    return eval_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c80f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = eval(ft_test_res, base_test_res, score_idx=0)\n",
    "eval_df.to_csv('evaluation/eval_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c121ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cca63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seed(1)\n",
    "base_test_res[:2]\n",
    "ft_test_res[:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
